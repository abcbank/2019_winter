# Face-based Applications
---
---
---
## Review
- Haar-like feathure + Adaboost + Cascade structure
  - Integral image for efficiently computing Haar-like features
  - Feature selection with Adaboosting
  - Boosting the detection speed with cascade structure

- Template matching with HOG descriptors
  - Detecting without learning

## Face Verification
- Verification: 같은지 다른지를 판단해주는 것
  - 일반적으로 이미지의 일부를 Deep Learning 기반 CNN에 집어넣어 찾는다
  - 빛의 명암 등 여러 문제를 고려해야한다.
  - PIE: phose, illumination, expression(형태, 명암, 표정)
  - FAR < 1/100K -> FAR: false acceptance rate
  - 사진, 마스크, 비디오 등 가짜를 구분할 수 있는 능력도 있어야한다.

## Technical Details
- Local Binary Pattern: encodes the binary pattern centered at the current pixel
  - 좋은 알고리즘임!
  - 정해진 픽셀에서 픽셀값과 8방향에 있는 값들을 비교한다. -> 크면 1 작으면 0
    - 원래 정해진 방향은 없지만 시험 등을 위해 12시부터 시계방향으로 돌아간다고 하자  현
  - 모든 픽셀에 대해 같은 알고리즘 수행 후 결과 출력
  - 빛에 강하다는 장점

## Nonlinear Optimization
- 사람의 얼굴은 일정하지 않음 -> 표정 등 여러가지 요인으로 바뀔 수 있음
- 이를 보안하기 위해, 몇가지 알고리즘을 추가해줘야함.
  ![nonlinear](./img/nonlinear_optimization.png)
  - X: 특정 좌표에서의 픽셀(X(x,y))
  - k: 시간축
  - $\Delta x$: nonlinear value -> 얘를 알아내는것이 중요하다.

### Newton Method
- X_0: initial status(픽셀 좌표계에 존재한다)
  ![Newton](./img/Newton_Method.png)]
  - 일정 거리를 이동했을 경우, 미분을 통해 해당 값이 이동한 정도를 대략적으로 알아낸다.
  - 특정 점에서 접선을 그었다 가정할때, 해당 함수는 y = ax + b 형태로 나타난다. 이때, 기울기는 f`(x)를 가지므로 해당 식을 통해 다음과 같은 결론을 도출할 수 있다.
    ```text
    f(x_1) = f`(x_1) * x_1 + b
    b = f(x_1) - f`(x_1) * x_1

    b := - f`(x_1) * x_2 이므로 (b는 x_1에서 )
    x_2 = x_1 - f(x_1) / f`(x_1)
    ```

- result
  ![landmark](./img/newton_landmark.png)
  - h(x): 예측한 위치
  - y: 실제 위치

### Supervised descent method
- 학습을 통해 유사점을 찾는다 -> 무수히 많은 데이터를 기반으로 어떤 경우에 어느정도 위치에 존재하는지 예측한다.
- hessian matrix와 newton matrix를 구할 필요 없으니 시간이 많이 단축된다.
  ![supervised_descent](./img/supervised_descent.png)
  - R_k의 값이 중요함 -> 이를 위해 학습을 시키는 것.

#### Technical Details
- d: total pixel size(픽셀 좌표계에 존재)
- d(X): landmark point
- h(d(x)): nonlinear feature extraction function h(e.g. HOG, LBP, etc)
  ![problemStatement](./img/supervised_problem_statement.png)
  - 예측한 위치(h(d(X_0 + delta_X))와 정답(h(d(X_*)))의 차이가 최소화하도록 해줘야한다.
  - 일반적인 경우를 가정 -> 급격한 변화가 없다고 가정하므로 테일러 변환을 쓸 수 있음
    ```text
    f(X + delta_X) = f(X_0) + f`(x_0) * delta_X + 1/(2!) * f``(x_0) * (delta_x)^2
    ```
    ![solution](./img/supervised_solution.png)
- General formulation for testing as well
  ```text
  delta_X = R_0(feature_cur - feature_next)
  -> 이떄, 학습 후 실제 적용할 경우, freature_next에 대한 정보가 없다. 따라서 적용이 어려움
  -> 적용이 어렵다면 상수로 바꿔버리자!
  
  delta_X = R_0(feature_cur - b_0)
  ```